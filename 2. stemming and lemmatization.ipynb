{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are text processing techniques to reduce inflected words (variations of a base word) to their common base form, but they achieve this in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming:\n",
    "\n",
    "Stemming is a rule-based approach that removes suffixes from words to obtain a morphological stem. <br><br>\n",
    "This stem might not necessarily be a real word, but it captures the core meaning of the inflected word. <br><br>\n",
    "For example, stemming the words \"running\", \"runs\", and \"ran\" would all result in the stem \"run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The: the\n",
      "quick: quick\n",
      "brown: brown\n",
      "foxes: fox\n",
      "are: are\n",
      "jumping: jump\n",
      "over: over\n",
      "the: the\n",
      "lazy: lazi\n",
      "dogs: dog\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "sentence = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "words = word_tokenize(sentence)\n",
    " \n",
    "for word in words:\n",
    "    print(word + \": \" + stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization:\n",
    "Lemmatization, on the other hand, takes a more linguistic approach. <br><br>\n",
    "It uses dictionaries and morphological analysis to map inflected words to their canonical form, also known as the lemma. <br><br>\n",
    "Unlike stemming, lemmatization always results in a valid word, ensuring consistency and accuracy. <br><br>\n",
    "For instance, lemmatizing \"changing\", \"changed\", and \"changes\" would all result in the lemma \"change\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The: the\n",
      "quick: quick\n",
      "brown: brown\n",
      "foxes: fox\n",
      "are: be\n",
      "jumping: jump\n",
      "over: over\n",
      "the: the\n",
      "lazy: lazy\n",
      "dogs: dog\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "text = nlp(text)\n",
    "\n",
    "lemmatized_tokens = [token.lemma_ for token in text]\n",
    "\n",
    "for original, lemmatized in zip(text,lemmatized_tokens):\n",
    "    print(str(original) + \": \" + lemmatized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
